{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOiht3v/Ve3b6bohaFQpGJR",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vijaygwu/systemdesign/blob/main/MultiStage.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Below is a simple Python example (using pandas) that demonstrates how to label positive vs. negative samples from the synthetic **interactions** dataset based on a compound engagement metric.\n",
        "\n",
        "Feel free to change the weights and threshold to best suit your use case.\n",
        "\n",
        "```python\n",
        "import pandas as pd\n",
        "\n",
        "# 1. Load the 'interactions.csv' dataset\n",
        "interactions = pd.read_csv(\"interactions.csv\")\n",
        "\n",
        "# 2. Define the tunable weights for each signal.\n",
        "#    You can modify these values (w1..w5) based on analysis or A/B testing.\n",
        "w1 = 1.0  # Weight for click\n",
        "w2 = 0.5  # Weight for (dwell_time / expected_dwell)\n",
        "w3 = 2.0  # Weight for share\n",
        "w4 = 1.0  # Weight for comment\n",
        "w5 = 1.0  # Weight for hide (subtracted)\n",
        "\n",
        "# 3. Decide on an 'expected_dwell' for normalizing dwell_time.\n",
        "#    This is just an example; you might compute it from actual data.\n",
        "expected_dwell = 10.0\n",
        "\n",
        "# 4. Compute a compound engagement score for each interaction row.\n",
        "#    - If dwell_time is missing or zero, it won't add much to the score.\n",
        "#    - Negative feedback (hide=1) will reduce the score.\n",
        "interactions[\"engagement_score\"] = (\n",
        "    w1 * interactions[\"click\"] +\n",
        "    w2 * (interactions[\"dwell_time\"] / expected_dwell) +\n",
        "    w3 * interactions[\"share\"] +\n",
        "    w4 * interactions[\"comment\"] -\n",
        "    w5 * interactions[\"hide\"]\n",
        ")\n",
        "\n",
        "# 5. Choose a threshold above which we consider an interaction 'positive'.\n",
        "#    For demonstration, we'll use threshold = 2.0, but you can tune it.\n",
        "threshold = 2.0\n",
        "\n",
        "# 6. Create a binary label: 1 for positive, 0 for negative.\n",
        "#    - Alternatively, you could store string labels like \"positive\" / \"negative\".\n",
        "interactions[\"label\"] = (interactions[\"engagement_score\"] > threshold).astype(int)\n",
        "\n",
        "# 7. Now 'interactions' has an added 'label' column indicating positive/negative.\n",
        "#    You can inspect, group, or merge it with user/content data as needed.\n",
        "print(interactions.head(10))\n",
        "\n",
        "# 8. (Optional) Save the updated DataFrame back to CSV\n",
        "interactions.to_csv(\"interactions_labeled.csv\", index=False)\n",
        "```\n",
        "\n",
        "### Explanation\n",
        "\n",
        "1. **Load the data**: The script reads the synthetic `interactions.csv` file into a pandas DataFrame.\n",
        "2. **Weights**: We define the contribution (importance) of each user action (`click`, `share`, etc.). You might calibrate these via offline experiments or hyperparameter searches.\n",
        "3. **Expected dwell**: Normalizes `dwell_time` since a 10-second view might be “long” for some platforms but trivial on others. You can refine this by computing an average or median dwell time from real data.\n",
        "4. **Compound engagement score**:\n",
        "   \\[\n",
        "     \\text{engagement\\_score}\n",
        "       = w_1 \\times \\text{click}\n",
        "         + w_2 \\times \\Bigl(\\frac{\\text{dwell\\_time}}{\\text{expected\\_dwell}}\\Bigr)\n",
        "         + w_3 \\times \\text{share}\n",
        "         + w_4 \\times \\text{comment}\n",
        "         - w_5 \\times \\text{hide}\n",
        "   \\]\n",
        "   - A `click` (1) adds `w1` points.  \n",
        "   - `dwell_time` is scaled down by `expected_dwell` then multiplied by `w2`.  \n",
        "   - A `share` significantly boosts the score (here `2.0` points each).  \n",
        "   - Each `comment` also contributes extra points.  \n",
        "   - A `hide` event subtracts points (penalizing negative feedback).\n",
        "5. **Threshold**: We pick `2.0` as a simple cutoff for whether an interaction is “highly engaged” (label=1) or not (label=0). In a production system, you might run `A/B` tests or user research to refine this threshold.\n",
        "6. **Label**: We store the result in a new column, `label`.\n",
        "7. **Further usage**: You can integrate these labeled interactions into a supervised learning pipeline, e.g., training a classification model or computing ranking metrics.\n",
        "\n",
        "This sample code should help you **label positive/negative samples** from your synthetic dataset in a way that aligns with the multi-stage ranking system described in the original reference. Adjust weights, threshold, and normalization to fit your specific application."
      ],
      "metadata": {
        "id": "qT4HrxOOi0WP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Below is a high-level walkthrough (with example code) of how you might train a simple Artificial Neural Network (ANN) on this synthetic dataset. The goal is to predict a user’s engagement (positive vs. negative) with a piece of content. We will:\n",
        "\n",
        "1. **Combine** the three CSVs (`users.csv`, `content.csv`, and `interactions.csv`).  \n",
        "2. **Create** features for both users and content.  \n",
        "3. **Join** them with the interaction records.  \n",
        "4. **Derive** the engagement label (e.g., using the compound engagement metric or the binary label column).  \n",
        "5. **Train** a simple feed-forward neural network (ANN) in Keras/PyTorch/etc.\n",
        "\n",
        "Below is a minimal example in **Python** using **pandas** for data wrangling, **scikit-learn** for transformations, and **TensorFlow/Keras** for the neural network. This is only a starting template—feel free to expand or refine.\n",
        "\n",
        "---\n",
        "\n",
        "## 1. Set Up the Project\n",
        "\n",
        "Make sure you have the following Python libraries installed:\n",
        "\n",
        "```bash\n",
        "pip install pandas scikit-learn tensorflow\n",
        "```\n",
        "\n",
        "(Or install PyTorch if you prefer. The core idea is the same.)\n",
        "\n",
        "---\n",
        "\n",
        "## 2. Load and Merge the Data\n",
        "\n",
        "```python\n",
        "import pandas as pd\n",
        "\n",
        "# 1. Load each CSV into a DataFrame\n",
        "users = pd.read_csv(\"users.csv\")\n",
        "content = pd.read_csv(\"content.csv\")\n",
        "interactions = pd.read_csv(\"interactions.csv\")\n",
        "\n",
        "# 2. Suppose we already have a 'label' column in interactions.csv\n",
        "#    (or we can compute one using the code from before).\n",
        "#    We'll assume \"label\" is binary: 1 => positive engagement, 0 => negative.\n",
        "\n",
        "# 3. Merge user features onto interactions\n",
        "#    - 'user_id' is the join key\n",
        "df = interactions.merge(users, how=\"inner\", on=\"user_id\")\n",
        "\n",
        "# 4. Merge content features onto the result\n",
        "#    - 'content_id' is the join key\n",
        "df = df.merge(content, how=\"inner\", on=\"content_id\")\n",
        "\n",
        "# Now 'df' has columns from users, content, and interactions plus the 'label'.\n",
        "print(df.head())\n",
        "```\n",
        "\n",
        "At this point, `df` contains a row for each user–content interaction, including user attributes (e.g., `device_type`, `region`, `topic_affinity_politics`, etc.), content attributes (e.g., `publisher`, `topic`, `quality_score`), as well as interaction signals (`click`, `dwell_time`, `share`, `hide`, etc.) and your final `label` (if you previously computed it or included it in `interactions.csv`).\n",
        "\n",
        "---\n",
        "\n",
        "## 3. Basic Feature Engineering\n",
        "\n",
        "We need to convert categorical fields (e.g., `device_type`, `region`, `publisher`, `topic`) into numeric encodings or embeddings, as a neural network can only work with numeric inputs. We also might scale numerical fields (like dwell time, topic affinities, quality scores).\n",
        "\n",
        "Below, we do a minimal approach using scikit-learn:  \n",
        "- **Label Encoding** or **One-Hot Encoding** for categorical columns.  \n",
        "- **Scaling** for numeric columns.\n",
        "\n",
        "```python\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
        "import numpy as np\n",
        "\n",
        "# Example: let's pick some columns to treat as numeric and others as categorical.\n",
        "num_cols = [\n",
        "    \"topic_affinity_politics\", \"topic_affinity_tech\", \"topic_affinity_sports\",\n",
        "    \"avg_session_length\", \"quality_score\", \"dwell_time\"\n",
        "]\n",
        "\n",
        "cat_cols = [\n",
        "    \"device_type\", \"region\", \"publisher\", \"topic\"\n",
        "]\n",
        "# Note: You could also treat 'user_id' and 'content_id' as categorical\n",
        "# and learn embeddings for them. For simplicity, we'll skip that here.\n",
        "\n",
        "# 1. Separate our final label from the features\n",
        "labels = df[\"label\"].values  # 0 or 1\n",
        "df_features = df[num_cols + cat_cols].copy()\n",
        "\n",
        "# 2. One-Hot encode categorical columns\n",
        "ohe = OneHotEncoder(sparse=False, handle_unknown=\"ignore\")\n",
        "cat_encoded = ohe.fit_transform(df_features[cat_cols])\n",
        "\n",
        "# 3. Scale numeric columns\n",
        "scaler = StandardScaler()\n",
        "num_scaled = scaler.fit_transform(df_features[num_cols])\n",
        "\n",
        "# 4. Concatenate numeric + one-hot-coded categorical arrays\n",
        "X = np.hstack([num_scaled, cat_encoded])\n",
        "\n",
        "# X is now a numeric matrix suitable for ANN input\n",
        "print(X.shape, labels.shape)  # e.g., (N, num_features), (N,)\n",
        "```\n",
        "\n",
        "> **In practice**: You might do more advanced transformations (e.g., embeddings for user IDs, content IDs, or hashing for `blocklist`) or incorporate engineered cross-features. This snippet only shows the basics.\n",
        "\n",
        "---\n",
        "\n",
        "## 4. Build a Simple Feed-Forward Neural Network\n",
        "\n",
        "Below is an example using **Keras** (TensorFlow) to define and train a minimal multi-layer perceptron (MLP) on the feature matrix `X` and label vector `labels`.\n",
        "\n",
        "```python\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "# 1. Define a small MLP\n",
        "model = keras.Sequential([\n",
        "    layers.Input(shape=(X.shape[1],)),   # input layer: dimension = # of features\n",
        "    layers.Dense(64, activation='relu'), # hidden layer\n",
        "    layers.Dense(32, activation='relu'), # another hidden layer\n",
        "    layers.Dense(1, activation='sigmoid') # output layer for binary classification\n",
        "])\n",
        "\n",
        "model.compile(\n",
        "    optimizer='adam',\n",
        "    loss='binary_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "# 2. Train/validation split\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_val, y_train, y_val = train_test_split(\n",
        "    X, labels, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# 3. Fit the model\n",
        "history = model.fit(\n",
        "    X_train, y_train,\n",
        "    validation_data=(X_val, y_val),\n",
        "    batch_size=32,\n",
        "    epochs=10\n",
        ")\n",
        "```\n",
        "\n",
        "This simple network tries to learn a mapping: \\(\\text{features} \\to \\text{probability of label=1}\\). After training, you can examine metrics:\n",
        "\n",
        "```python\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(history.history[\"loss\"], label=\"Train Loss\")\n",
        "plt.plot(history.history[\"val_loss\"], label=\"Val Loss\")\n",
        "plt.legend()\n",
        "plt.show()\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## 5. Evaluate the Model\n",
        "\n",
        "Besides looking at training/validation loss and accuracy, you might also compute:\n",
        "\n",
        "- **Precision, Recall, F1**  \n",
        "- **AUC (Area Under ROC Curve)**  \n",
        "- **Calibration** (if your use case cares about well-calibrated probabilities)  \n",
        "\n",
        "For example:\n",
        "\n",
        "```python\n",
        "from sklearn.metrics import classification_report, roc_auc_score\n",
        "\n",
        "y_val_pred = (model.predict(X_val) > 0.5).astype(int).ravel()\n",
        "print(classification_report(y_val, y_val_pred, digits=4))\n",
        "\n",
        "y_val_probs = model.predict(X_val).ravel()  # get raw probabilities\n",
        "print(\"AUC:\", roc_auc_score(y_val, y_val_probs))\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## 6. Going Further\n",
        "\n",
        "1. **Learnable Embeddings** for user/content IDs:  \n",
        "   - Instead of one-hot-encoding user or content IDs, you can feed them into a learned embedding layer in Keras or PyTorch. This is common in recommender systems (similar to collaborative filtering neural approaches).  \n",
        "2. **Sequence/Context Modeling**:  \n",
        "   - If you want to capture the user’s session history, you could build a model that processes a sequence of user interactions (via an RNN or Transformer).  \n",
        "3. **Multi-Task Learning**:  \n",
        "   - If you have multiple engagement signals (click, share, dwell, etc.) you can define separate output heads and train them together.  \n",
        "\n",
        "---\n",
        "\n",
        "## Summary\n",
        "\n",
        "- **Join** all data: user + content + interactions + (optionally) computed labels.  \n",
        "- **Encode** categorical fields, scale numeric fields.  \n",
        "- **Train** an ANN in Keras (or another framework) using the resulting numeric matrix.  \n",
        "- **Adjust** your architecture, hyperparameters, and feature transformations as you iterate.  \n",
        "\n",
        "This pipeline is just the starting point. In production-scale systems, you might rely on a multi-stage process (ANN for final ranking, GBDT for initial ranking, etc.), plus advanced feature engineering and real-time pipelines. However, the example above demonstrates the core idea for how to feed the synthetic dataset into an ANN-based classifier or ranking model."
      ],
      "metadata": {
        "id": "aP8yLi9KnXCm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Below is a simple Python example (using pandas) that demonstrates how to label positive vs. negative samples from the synthetic **interactions** dataset based on a compound engagement metric.\n",
        "\n",
        "Feel free to change the weights and threshold to best suit your use case.\n",
        "\n",
        "```python\n",
        "import pandas as pd\n",
        "\n",
        "# 1. Load the 'interactions.csv' dataset\n",
        "interactions = pd.read_csv(\"interactions.csv\")\n",
        "\n",
        "# 2. Define the tunable weights for each signal.\n",
        "#    You can modify these values (w1..w5) based on analysis or A/B testing.\n",
        "w1 = 1.0  # Weight for click\n",
        "w2 = 0.5  # Weight for (dwell_time / expected_dwell)\n",
        "w3 = 2.0  # Weight for share\n",
        "w4 = 1.0  # Weight for comment\n",
        "w5 = 1.0  # Weight for hide (subtracted)\n",
        "\n",
        "# 3. Decide on an 'expected_dwell' for normalizing dwell_time.\n",
        "#    This is just an example; you might compute it from actual data.\n",
        "expected_dwell = 10.0\n",
        "\n",
        "# 4. Compute a compound engagement score for each interaction row.\n",
        "#    - If dwell_time is missing or zero, it won't add much to the score.\n",
        "#    - Negative feedback (hide=1) will reduce the score.\n",
        "interactions[\"engagement_score\"] = (\n",
        "    w1 * interactions[\"click\"] +\n",
        "    w2 * (interactions[\"dwell_time\"] / expected_dwell) +\n",
        "    w3 * interactions[\"share\"] +\n",
        "    w4 * interactions[\"comment\"] -\n",
        "    w5 * interactions[\"hide\"]\n",
        ")\n",
        "\n",
        "# 5. Choose a threshold above which we consider an interaction 'positive'.\n",
        "#    For demonstration, we'll use threshold = 2.0, but you can tune it.\n",
        "threshold = 2.0\n",
        "\n",
        "# 6. Create a binary label: 1 for positive, 0 for negative.\n",
        "#    - Alternatively, you could store string labels like \"positive\" / \"negative\".\n",
        "interactions[\"label\"] = (interactions[\"engagement_score\"] > threshold).astype(int)\n",
        "\n",
        "# 7. Now 'interactions' has an added 'label' column indicating positive/negative.\n",
        "#    You can inspect, group, or merge it with user/content data as needed.\n",
        "print(interactions.head(10))\n",
        "\n",
        "# 8. (Optional) Save the updated DataFrame back to CSV\n",
        "interactions.to_csv(\"interactions_labeled.csv\", index=False)\n",
        "```\n",
        "\n",
        "### Explanation\n",
        "\n",
        "1. **Load the data**: The script reads the synthetic `interactions.csv` file into a pandas DataFrame.\n",
        "2. **Weights**: We define the contribution (importance) of each user action (`click`, `share`, etc.). You might calibrate these via offline experiments or hyperparameter searches.\n",
        "3. **Expected dwell**: Normalizes `dwell_time` since a 10-second view might be “long” for some platforms but trivial on others. You can refine this by computing an average or median dwell time from real data.\n",
        "4. **Compound engagement score**:\n",
        "   \\[\n",
        "     \\text{engagement\\_score}\n",
        "       = w_1 \\times \\text{click}\n",
        "         + w_2 \\times \\Bigl(\\frac{\\text{dwell\\_time}}{\\text{expected\\_dwell}}\\Bigr)\n",
        "         + w_3 \\times \\text{share}\n",
        "         + w_4 \\times \\text{comment}\n",
        "         - w_5 \\times \\text{hide}\n",
        "   \\]\n",
        "   - A `click` (1) adds `w1` points.  \n",
        "   - `dwell_time` is scaled down by `expected_dwell` then multiplied by `w2`.  \n",
        "   - A `share` significantly boosts the score (here `2.0` points each).  \n",
        "   - Each `comment` also contributes extra points.  \n",
        "   - A `hide` event subtracts points (penalizing negative feedback).\n",
        "5. **Threshold**: We pick `2.0` as a simple cutoff for whether an interaction is “highly engaged” (label=1) or not (label=0). In a production system, you might run `A/B` tests or user research to refine this threshold.\n",
        "6. **Label**: We store the result in a new column, `label`.\n",
        "7. **Further usage**: You can integrate these labeled interactions into a supervised learning pipeline, e.g., training a classification model or computing ranking metrics.\n",
        "\n",
        "This sample code should help you **label positive/negative samples** from your synthetic dataset in a way that aligns with the multi-stage ranking system described in the original reference. Adjust weights, threshold, and normalization to fit your specific application."
      ],
      "metadata": {
        "id": "QNrCRHBjkwOp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# 1. Load the 'interactions.csv' dataset\n",
        "interactions = pd.read_csv(\"/content/sample_data/Interaction.csv\")\n",
        "\n",
        "# 2. Define the tunable weights for each signal.\n",
        "#    You can modify these values (w1..w5) based on analysis or A/B testing.\n",
        "w1 = 1.0  # Weight for click\n",
        "w2 = 0.5  # Weight for (dwell_time / expected_dwell)\n",
        "w3 = 2.0  # Weight for share\n",
        "w4 = 1.0  # Weight for comment\n",
        "w5 = 1.0  # Weight for hide (subtracted)\n",
        "\n",
        "# 3. Decide on an 'expected_dwell' for normalizing dwell_time.\n",
        "#    This is just an example; you might compute it from actual data.\n",
        "expected_dwell = 10.0\n",
        "\n",
        "# 4. Compute a compound engagement score for each interaction row.\n",
        "#    - If dwell_time is missing or zero, it won't add much to the score.\n",
        "#    - Negative feedback (hide=1) will reduce the score.\n",
        "interactions[\"engagement_score\"] = (\n",
        "    w1 * interactions[\"click\"] +\n",
        "    w2 * (interactions[\"dwell_time\"] / expected_dwell) +\n",
        "    w3 * interactions[\"share\"] +\n",
        "    w4 * interactions[\"comment\"] -\n",
        "    w5 * interactions[\"hide\"]\n",
        ")\n",
        "\n",
        "# 5. Choose a threshold above which we consider an interaction 'positive'.\n",
        "#    For demonstration, we'll use threshold = 2.0, but you can tune it.\n",
        "threshold = 2.0\n",
        "\n",
        "# 6. Create a binary label: 1 for positive, 0 for negative.\n",
        "#    - Alternatively, you could store string labels like \"positive\" / \"negative\".\n",
        "interactions[\"label\"] = (interactions[\"engagement_score\"] > threshold).astype(int)\n",
        "\n",
        "# 7. Now 'interactions' has an added 'label' column indicating positive/negative.\n",
        "#    You can inspect, group, or merge it with user/content data as needed.\n",
        "print(interactions.head(10))\n",
        "\n",
        "# 8. (Optional) Save the updated DataFrame back to CSV\n",
        "interactions.to_csv(\"/content/sample_data/interactions_labeled.csv\", index=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZkfuG5jyj5lm",
        "outputId": "325edc74-7813-4f59-ae7c-c83a7f63091a"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   user_id  content_id  click  dwell_time  share  comment  hide  \\\n",
            "0        1         101      1        12.4      0        1     0   \n",
            "1        1         108      1        15.0      1        0     0   \n",
            "2        2         101      1         5.1      0        0     0   \n",
            "3        2         104      0         0.0      0        0     1   \n",
            "4        3         136      0         3.2      0        0     0   \n",
            "5        3         107      1         7.0      1        1     0   \n",
            "6        4         110      1         9.5      0        2     0   \n",
            "7        4         104      1        10.2      0        2     0   \n",
            "8        5         103      1         9.4      1        0     0   \n",
            "9        5         107      1         5.0      0        0     0   \n",
            "\n",
            "        event_timestamp  engagement_score  label  \n",
            "0  2025-04-01T09:00:00Z             2.620      1  \n",
            "1  2025-04-01T10:45:00Z             3.750      1  \n",
            "2  2025-04-01T09:10:00Z             1.255      0  \n",
            "3  2025-04-01T13:05:00Z            -1.000      0  \n",
            "4  2025-04-02T14:50:00Z             0.160      0  \n",
            "5  2025-04-01T15:30:00Z             4.350      1  \n",
            "6  2025-04-01T13:30:00Z             3.475      1  \n",
            "7  2025-04-01T13:35:00Z             3.510      1  \n",
            "8  2025-04-01T11:30:00Z             3.470      1  \n",
            "9  2025-04-01T15:10:00Z             1.250      0  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# 1. Load each CSV into a DataFrame\n",
        "users = pd.read_csv(\"/content/sample_data/Users.csv\")\n",
        "content = pd.read_csv(\"/content/sample_data/Content.csv\")\n",
        "interactions = pd.read_csv(\"/content/sample_data/interactions_labeled.csv\")\n",
        "\n",
        "# 2. Suppose we already have a 'label' column in interactions.csv\n",
        "#    (or we can compute one using the code from before).\n",
        "#    We'll assume \"label\" is binary: 1 => positive engagement, 0 => negative.\n",
        "\n",
        "# 3. Merge user features onto interactions\n",
        "#    - 'user_id' is the join key\n",
        "df = interactions.merge(users, how=\"inner\", on=\"user_id\")\n",
        "\n",
        "# 4. Merge content features onto the result\n",
        "#    - 'content_id' is the join key\n",
        "df = df.merge(content, how=\"inner\", on=\"content_id\")\n",
        "\n",
        "# Now 'df' has columns from users, content, and interactions plus the 'label'.\n",
        "print(df.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R39Su702k1Vl",
        "outputId": "873c9089-9a43-41b0-c3ed-5b472e840593"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   user_id  content_id  click  dwell_time  share  comment  hide  \\\n",
            "0        1         101      1        12.4      0        1     0   \n",
            "1        1         108      1        15.0      1        0     0   \n",
            "2        2         101      1         5.1      0        0     0   \n",
            "3        2         104      0         0.0      0        0     1   \n",
            "4        3         136      0         3.2      0        0     0   \n",
            "\n",
            "        event_timestamp  engagement_score  label  ... topic_affinity_politics  \\\n",
            "0  2025-04-01T09:00:00Z             2.620      1  ...                    0.77   \n",
            "1  2025-04-01T10:45:00Z             3.750      1  ...                    0.77   \n",
            "2  2025-04-01T09:10:00Z             1.255      0  ...                    0.34   \n",
            "3  2025-04-01T13:05:00Z            -1.000      0  ...                    0.34   \n",
            "4  2025-04-02T14:50:00Z             0.160      0  ...                    0.02   \n",
            "\n",
            "  topic_affinity_tech  topic_affinity_sports  avg_session_length    blocklist  \\\n",
            "0                0.12                   0.58                8.94          NaN   \n",
            "1                0.12                   0.58                8.94          NaN   \n",
            "2                0.86                   0.47                3.93  publisher_x   \n",
            "3                0.86                   0.47                3.93  publisher_x   \n",
            "4                0.63                   0.91                4.81          NaN   \n",
            "\n",
            "      publisher       topic quality_score region_restriction  \\\n",
            "0  TheDailyNews    politics          0.90                NaN   \n",
            "1      TechGuru  technology          0.84                ALL   \n",
            "2  TheDailyNews    politics          0.90                NaN   \n",
            "3   InsightPost    politics          0.93                NaN   \n",
            "4       NewsNow    business          0.45                NaN   \n",
            "\n",
            "      publish_timestamp  \n",
            "0  2025-04-01T08:20:00Z  \n",
            "1  2025-04-01T16:25:00Z  \n",
            "2  2025-04-01T08:20:00Z  \n",
            "3  2025-04-01T12:00:00Z  \n",
            "4  2025-04-02T14:30:00Z  \n",
            "\n",
            "[5 rows x 22 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install pandas scikit-learn tensorflow\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QoZO9HSflx01",
        "outputId": "aab4436b-3bb2-4cfc-e3cf-48839f9087a0"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.11/dist-packages (2.18.0)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.14.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (25.2.10)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (5.29.4)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow) (75.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.0.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (4.13.1)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.2)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.71.0)\n",
            "Requirement already satisfied: tensorboard<2.19,>=2.18 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.18.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.8.0)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.13.0)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.4.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.0.8)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.15.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2025.1.31)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
        "import numpy as np\n",
        "\n",
        "# Example: let's pick some columns to treat as numeric and others as categorical.\n",
        "num_cols = [\n",
        "    \"topic_affinity_politics\", \"topic_affinity_tech\", \"topic_affinity_sports\",\n",
        "    \"avg_session_length\", \"quality_score\", \"dwell_time\"\n",
        "]\n",
        "\n",
        "cat_cols = [\n",
        "    \"device_type\", \"region\", \"publisher\", \"topic\"\n",
        "]\n",
        "# Note: You could also treat 'user_id' and 'content_id' as categorical\n",
        "# and learn embeddings for them. For simplicity, we'll skip that here.\n",
        "\n",
        "# 1. Separate our final label from the features\n",
        "labels = df[\"label\"].values  # 0 or 1\n",
        "df_features = df[num_cols + cat_cols].copy()\n",
        "\n",
        "# 2. One-Hot encode categorical columns\n",
        "ohe = OneHotEncoder(handle_unknown=\"ignore\")\n",
        "cat_encoded = ohe.fit_transform(df_features[cat_cols]).toarray()\n",
        "\n",
        "# 3. Scale numeric columns\n",
        "scaler = StandardScaler()\n",
        "num_scaled = scaler.fit_transform(df_features[num_cols])\n",
        "\n",
        "# 4. Concatenate numeric + one-hot-coded categorical arrays\n",
        "X = np.hstack([num_scaled, cat_encoded])\n",
        "\n",
        "# X is now a numeric matrix suitable for ANN input\n",
        "print(X.shape, labels.shape)  # e.g., (N, num_features), (N,)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "szzET7_WliII",
        "outputId": "1c6491a7-64d5-421a-a907-c83244eeb7dd"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(106, 30) (106,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "# 1. Define a small MLP\n",
        "model = keras.Sequential([\n",
        "    layers.Input(shape=(X.shape[1],)),   # input layer: dimension = # of features\n",
        "    layers.Dense(64, activation='relu'), # hidden layer\n",
        "    layers.Dense(32, activation='relu'), # another hidden layer\n",
        "    layers.Dense(1, activation='sigmoid') # output layer for binary classification\n",
        "])\n",
        "\n",
        "model.compile(\n",
        "    optimizer='adam',\n",
        "    loss='binary_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "# 2. Train/validation split\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_val, y_train, y_val = train_test_split(\n",
        "    X, labels, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# 3. Fit the model\n",
        "history = model.fit(\n",
        "    X_train, y_train,\n",
        "    validation_data=(X_val, y_val),\n",
        "    batch_size=32,\n",
        "    epochs=10\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XkHFp2awmZV3",
        "outputId": "12fd7354-a356-4018-a46d-64ca3a8fd9d8"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 148ms/step - accuracy: 0.4725 - loss: 0.6973 - val_accuracy: 0.4091 - val_loss: 0.7115\n",
            "Epoch 2/10\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.5768 - loss: 0.6655 - val_accuracy: 0.5455 - val_loss: 0.6965\n",
            "Epoch 3/10\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.7241 - loss: 0.6294 - val_accuracy: 0.5455 - val_loss: 0.6839\n",
            "Epoch 4/10\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.7186 - loss: 0.6163 - val_accuracy: 0.5909 - val_loss: 0.6725\n",
            "Epoch 5/10\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.7264 - loss: 0.6033 - val_accuracy: 0.5909 - val_loss: 0.6630\n",
            "Epoch 6/10\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.7675 - loss: 0.5626 - val_accuracy: 0.5909 - val_loss: 0.6558\n",
            "Epoch 7/10\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.7520 - loss: 0.5687 - val_accuracy: 0.5455 - val_loss: 0.6494\n",
            "Epoch 8/10\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.7755 - loss: 0.5296 - val_accuracy: 0.5455 - val_loss: 0.6445\n",
            "Epoch 9/10\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.7755 - loss: 0.5170 - val_accuracy: 0.5455 - val_loss: 0.6391\n",
            "Epoch 10/10\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.7971 - loss: 0.4904 - val_accuracy: 0.5455 - val_loss: 0.6337\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report, roc_auc_score\n",
        "\n",
        "y_val_pred = (model.predict(X_val) > 0.5).astype(int).ravel()\n",
        "print(classification_report(y_val, y_val_pred, digits=4))\n",
        "\n",
        "y_val_probs = model.predict(X_val).ravel()  # get raw probabilities\n",
        "print(\"AUC:\", roc_auc_score(y_val, y_val_probs))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PJOIYzYVmwSc",
        "outputId": "f9d0a42b-4211-42bf-dd28-cb5b54334a48"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 229ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.6000    0.8571    0.7059        14\n",
            "           1     0.0000    0.0000    0.0000         8\n",
            "\n",
            "    accuracy                         0.5455        22\n",
            "   macro avg     0.3000    0.4286    0.3529        22\n",
            "weighted avg     0.3818    0.5455    0.4492        22\n",
            "\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 227ms/step\n",
            "AUC: 0.6607142857142857\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Below is a **conceptual walkthrough** (with **example code**) demonstrating how to do a *multistage ranking* pipeline using the synthetic dataset (users, content, interactions) you already have.\n",
        "\n",
        "---\n",
        "\n",
        "# Overview\n",
        "\n",
        "A typical **multistage ranking** system looks like this:\n",
        "\n",
        "1. **Candidate Generation (Stage 1)**  \n",
        "   - Narrow down the huge pool of content (potentially thousands/millions) to a smaller set (e.g., a few hundred).  \n",
        "   - Often done with simpler or specialized methods (ANN embeddings, collaborative filtering, etc.).\n",
        "\n",
        "2. **Initial Ranking (Stage 2)**  \n",
        "   - A moderately complex model (e.g., a Gradient Boosted Decision Tree, or GBDT) that scores and sorts these candidates.  \n",
        "   - Fast and interpretable with moderate accuracy.\n",
        "\n",
        "3. **Final / Deep Ranking (Stage 3)**  \n",
        "   - A more sophisticated (often neural) model that re-ranks the top \\(N\\) from Stage 2.  \n",
        "   - Captures complex interactions (e.g., deep user–content embeddings, sequential signals) but is more expensive.\n",
        "\n",
        "Here, we’ll do a **toy example** with Python + scikit-learn + Keras to illustrate the concept using your synthetic dataset. Feel free to adapt or swap out parts (e.g., use PyTorch or LightGBM) to suit your environment.\n",
        "\n",
        "---\n",
        "\n",
        "# 1. Setup and Data Loading\n",
        "\n",
        "```python\n",
        "import pandas as pd\n",
        "\n",
        "# Load the CSVs\n",
        "users = pd.read_csv(\"users.csv\")          # 100 rows\n",
        "content = pd.read_csv(\"content.csv\")      # 100 rows\n",
        "interactions = pd.read_csv(\"interactions.csv\")  # 100 rows, each row is a user-content interaction\n",
        "\n",
        "# We'll assume we already computed or added a 'label' in interactions\n",
        "# via a compound engagement metric or a threshold approach.\n",
        "# If not, see earlier instructions for how to generate 'label'.\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "# 2. Candidate Generation (Stage 1)\n",
        "\n",
        "**Objective**: Quickly reduce the total number of content items to a smaller subset per user. In a real system, you might do:\n",
        "- **Approximate Nearest Neighbor** on embeddings, or  \n",
        "- **Collaborative Filtering** to find likely relevant items.\n",
        "\n",
        "For this toy example, let’s do a **naïve “topic-match”** approach:  \n",
        "1. Extract each user’s “topic affinity” (politics, tech, sports) from `users.csv`.  \n",
        "2. Compare it to the content’s declared topic in `content.csv`, awarding a simple score.  \n",
        "3. Select the top-K items for each user as “candidates.”\n",
        "\n",
        "### 2.1 Build a Simple “Topic Score”\n",
        "\n",
        "```python\n",
        "import numpy as np\n",
        "\n",
        "# Let's create a quick map: if content['topic'] == 'politics', we align with user topic_affinity_politics, etc.\n",
        "# We'll do a function that given a user row and content row, returns a naive \"match\" score.\n",
        "def naive_topic_score(user_row, content_row):\n",
        "    topic = content_row[\"topic\"]\n",
        "    if topic == \"politics\":\n",
        "        return user_row[\"topic_affinity_politics\"]\n",
        "    elif topic == \"technology\":\n",
        "        return user_row[\"topic_affinity_tech\"]\n",
        "    elif topic == \"sports\":\n",
        "        return user_row[\"topic_affinity_sports\"]\n",
        "    # ... in your real system you'd handle other topics (business, entertainment, etc.)\n",
        "    # We'll just return 0 if it's not one of those three.\n",
        "    else:\n",
        "        return 0.0\n",
        "\n",
        "# We also might want to filter out content if user is in a different region,\n",
        "# or if content has region_restriction that doesn't match the user, etc.\n",
        "# For simplicity, let's skip it or do a quick check.\n",
        "```\n",
        "\n",
        "### 2.2 Generate Candidates\n",
        "\n",
        "Let’s say we want to find the **top 20** candidate items for each user.\n",
        "\n",
        "```python\n",
        "user_ids = users[\"user_id\"].unique()\n",
        "content_ids = content[\"content_id\"].unique()\n",
        "\n",
        "candidate_dict = {}  # key: user_id, value: list of top content_id\n",
        "\n",
        "for uid in user_ids:\n",
        "    # Grab user row\n",
        "    user_row = users[users[\"user_id\"] == uid].iloc[0]\n",
        "    \n",
        "    # For each piece of content, compute naive score\n",
        "    scores = []\n",
        "    for cid in content_ids:\n",
        "        c_row = content[content[\"content_id\"] == cid].iloc[0]\n",
        "        score = naive_topic_score(user_row, c_row)\n",
        "        scores.append((cid, score))\n",
        "    \n",
        "    # Sort by descending score, pick top 20\n",
        "    scores.sort(key=lambda x: x[1], reverse=True)\n",
        "    top_candidates = [cid for (cid, sc) in scores[:20]]\n",
        "    candidate_dict[uid] = top_candidates\n",
        "\n",
        "# candidate_dict[u] now holds the list of content IDs for that user\n",
        "# In a real pipeline, you'd store these somewhere or proceed to Stage 2 next.\n",
        "```\n",
        "\n",
        "Note: For a real system, you’d do this with vector embeddings or CF to handle scale. This naive approach is fine for a small synthetic dataset demonstration.\n",
        "\n",
        "---\n",
        "\n",
        "# 3. Initial Ranking (Stage 2)\n",
        "\n",
        "**Objective**: Score the *shortlisted candidates* with a moderately complex model (e.g., GBDT) that’s faster to run than a large neural net but more accurate than naive topic matching.\n",
        "\n",
        "We’ll do the following:\n",
        "\n",
        "1. Create training data from **interactions** for those user–content pairs that actually happened.  \n",
        "2. Train a **scikit-learn** GBDT (e.g., XGBoost or LightGBM) to predict the user’s engagement label.  \n",
        "3. At inference time, for each user’s candidate list, we generate the same features used in training, run them through the GBDT, and rank the content by predicted engagement probability.\n",
        "\n",
        "### 3.1 Build Training Data for GBDT\n",
        "\n",
        "We want user + content features => label. Let’s do a small set of numeric features:\n",
        "\n",
        "- **User**: `topic_affinity_politics`, `topic_affinity_tech`, `topic_affinity_sports`  \n",
        "- **Content**: `quality_score`  \n",
        "- **Interaction**: we can also include `click`, `dwell_time`, etc., if it’s historically known—but typically Stage 2 is trained offline on *past interactions*.\n",
        "\n",
        "```python\n",
        "import xgboost as xgb   # or \"import lightgbm as lgb\"\n",
        "\n",
        "# 1. Merge interactions with user and content data to get columns\n",
        "df_merged = interactions.merge(users, on=\"user_id\").merge(content, on=\"content_id\")\n",
        "\n",
        "# 2. We'll assume 'label' is in interactions. If you haven't computed it, do so first.\n",
        "#    If 'label' doesn't exist, see earlier code for computing a compound engagement metric threshold.\n",
        "\n",
        "# 3. We'll pick a few columns to be our features\n",
        "feature_cols = [\n",
        "    \"topic_affinity_politics\",\n",
        "    \"topic_affinity_tech\",\n",
        "    \"topic_affinity_sports\",\n",
        "    \"quality_score\"\n",
        "]\n",
        "X_data = df_merged[feature_cols]\n",
        "y_data = df_merged[\"label\"]  # 0 or 1\n",
        "\n",
        "# 4. Train/validation split\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_data, y_data, test_size=0.2, random_state=42)\n",
        "\n",
        "# 5. Train a basic XGBoost model\n",
        "gbdt = xgb.XGBClassifier(\n",
        "    n_estimators=100,\n",
        "    max_depth=3,\n",
        "    learning_rate=0.1,\n",
        "    use_label_encoder=False,\n",
        "    eval_metric=\"logloss\",\n",
        "    random_state=42\n",
        ")\n",
        "gbdt.fit(X_train, y_train, eval_set=[(X_val, y_val)], early_stopping_rounds=5)\n",
        "\n",
        "# Let's check accuracy quickly\n",
        "from sklearn.metrics import accuracy_score\n",
        "y_val_pred = gbdt.predict(X_val)\n",
        "acc = accuracy_score(y_val, y_val_pred)\n",
        "print(\"Validation Accuracy:\", acc)\n",
        "```\n",
        "\n",
        "### 3.2 Use the GBDT to Score Candidates\n",
        "\n",
        "Now that the GBDT is trained, we can *score* any user–content pair. In a multi-stage pipeline:\n",
        "\n",
        "- We look at the user’s top 20 (from candidate generation).\n",
        "- Build the same feature columns.\n",
        "- Run `gbdt.predict_proba(...)` to get probability of engagement.\n",
        "\n",
        "```python\n",
        "def gbdt_score_candidates(uid, candidate_list):\n",
        "    \"\"\"\n",
        "    Takes a user_id and a list of candidate content IDs.\n",
        "    Returns a list of (content_id, predicted_score).\n",
        "    \"\"\"\n",
        "    # find user row\n",
        "    user_row = users[users[\"user_id\"] == uid].iloc[0]\n",
        "    \n",
        "    results = []\n",
        "    for cid in candidate_list:\n",
        "        c_row = content[content[\"content_id\"] == cid].iloc[0]\n",
        "        \n",
        "        # build same features\n",
        "        row_feats = {\n",
        "            \"topic_affinity_politics\": user_row[\"topic_affinity_politics\"],\n",
        "            \"topic_affinity_tech\": user_row[\"topic_affinity_tech\"],\n",
        "            \"topic_affinity_sports\": user_row[\"topic_affinity_sports\"],\n",
        "            \"quality_score\": c_row[\"quality_score\"]\n",
        "        }\n",
        "        \n",
        "        # convert to DataFrame\n",
        "        single_df = pd.DataFrame([row_feats])\n",
        "        \n",
        "        # predict probability\n",
        "        proba = gbdt.predict_proba(single_df)[0,1]  # class=1 probability\n",
        "        results.append((cid, proba))\n",
        "    \n",
        "    # Sort by descending proba\n",
        "    results.sort(key=lambda x: x[1], reverse=True)\n",
        "    return results\n",
        "\n",
        "# Example usage for user 1:\n",
        "top_20 = candidate_dict[1]  # from Stage 1\n",
        "stage2_ranked = gbdt_score_candidates(uid=1, candidate_list=top_20)\n",
        "print(\"GBDT Stage2 Ranking for User 1:\", stage2_ranked)\n",
        "```\n",
        "\n",
        "That’s the **Stage 2** ranking output: a list of `(content_id, predicted_score)`.\n",
        "\n",
        "---\n",
        "\n",
        "# 4. Final / Deep Ranking (Stage 3)\n",
        "\n",
        "**Objective**: Re-rank the top \\(M\\) items (e.g., top 5 or top 10 from Stage 2) with a more computationally expensive model (like a neural network) that can capture deeper interactions.\n",
        "\n",
        "### 4.1 Train a Neural Network on Historical Data\n",
        "\n",
        "Similar to Stage 2, we can train a feed-forward (or any advanced) neural net. Let’s do a simple example in Keras:\n",
        "\n",
        "```python\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import numpy as np\n",
        "\n",
        "# We'll reuse df_merged from above (the joined user+content+interaction dataset).\n",
        "X_data_nn = df_merged[feature_cols].values\n",
        "y_data_nn = df_merged[\"label\"].values\n",
        "\n",
        "# Train/val split\n",
        "X_train_nn, X_val_nn, y_train_nn, y_val_nn = train_test_split(X_data_nn, y_data_nn, test_size=0.2, random_state=42)\n",
        "\n",
        "# Build a small ANN\n",
        "model = keras.Sequential([\n",
        "    layers.Input(shape=(len(feature_cols),)),\n",
        "    layers.Dense(16, activation='relu'),\n",
        "    layers.Dense(8, activation='relu'),\n",
        "    layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "model.fit(X_train_nn, y_train_nn, validation_data=(X_val_nn, y_val_nn), epochs=10, batch_size=32)\n",
        "```\n",
        "\n",
        "### 4.2 Re-rank the Top Items from Stage 2\n",
        "\n",
        "At inference time for user \\(u\\):\n",
        "\n",
        "1. Take the **top \\(M\\) items** from Stage 2’s results (e.g., top 5).  \n",
        "2. Build the same features, run them through the trained neural net’s `model.predict(...)`.  \n",
        "3. Sort by the neural net’s predicted probability.\n",
        "\n",
        "```python\n",
        "def nn_score_candidates(uid, candidate_list):\n",
        "    results = []\n",
        "    user_row = users[users[\"user_id\"] == uid].iloc[0]\n",
        "    \n",
        "    for cid in candidate_list:\n",
        "        c_row = content[content[\"content_id\"] == cid].iloc[0]\n",
        "        row_feats = [\n",
        "            user_row[\"topic_affinity_politics\"],\n",
        "            user_row[\"topic_affinity_tech\"],\n",
        "            user_row[\"topic_affinity_sports\"],\n",
        "            c_row[\"quality_score\"],\n",
        "        ]\n",
        "        X_input = np.array([row_feats], dtype=float)\n",
        "        prob = model.predict(X_input)[0,0]  # single numeric\n",
        "        results.append((cid, prob))\n",
        "    \n",
        "    # sort descending\n",
        "    results.sort(key=lambda x: x[1], reverse=True)\n",
        "    return results\n",
        "\n",
        "# Let's say from Stage 2 we took the top 5:\n",
        "stage2_top5 = stage2_ranked[:5]  # [(cid, score), (cid, score), ...]\n",
        "final_stage3 = nn_score_candidates(uid=1, candidate_list=[cid for cid,_ in stage2_top5])\n",
        "\n",
        "print(\"Stage 3 Final Ranking for User 1:\", final_stage3)\n",
        "```\n",
        "\n",
        "**Now** you have a 3-stage pipeline:\n",
        "1. Candidate generation with naive topic matching (Stage 1).  \n",
        "2. GBDT ranking on the top 20 (Stage 2).  \n",
        "3. DNN re-ranking on the top 5 from Stage 2 (Stage 3).  \n",
        "\n",
        "---\n",
        "\n",
        "# 5. Observations & Next Steps\n",
        "\n",
        "- This example is **toy-scale**: Our dataset only has 100 users, 100 content items, and 100 interactions. In real systems, you might have millions.  \n",
        "- **Candidate Generation** in production is often specialized: approximate nearest neighbor embeddings or high-performance collaborative filtering solutions.  \n",
        "- **Stage 2** might use a library like LightGBM or XGBoost with many more features (e.g., dwell time, user–publisher affinity).  \n",
        "- **Stage 3** can be a more advanced **deep architecture** (multi-task, embedding-based, sequence-based, or multi-head attention).  \n",
        "- You might do **A/B Testing** at each stage to ensure each refinement truly improves final user engagement or retention.  \n",
        "- **Real-time** integration includes caching, streaming feature updates, parallel inference, etc.\n",
        "\n",
        "---\n",
        "\n",
        "## Summary\n",
        "\n",
        "1. **Candidate Generation** (Stage 1):  \n",
        "   - Quickly narrow down potential items for each user.  \n",
        "2. **Initial Ranking** (Stage 2):  \n",
        "   - A moderate model (GBDT) that’s faster to infer but still fairly accurate.  \n",
        "3. **Final/Deep Ranking** (Stage 3):  \n",
        "   - A more computationally expensive model (e.g., neural net) that re-ranks the top items from Stage 2.\n",
        "\n",
        "With the sample code above, you can see how to **build & train** multiple models on the synthetic dataset, **score** user–content pairs with each model, and **chain** the results for a multistage ranking pipeline. In a real system, you would refine the data pipeline, add more advanced features, handle very large data, and measure performance using robust offline/online metrics—but this demonstration illustrates the core ideas of how “multistage ranking” is done in practice."
      ],
      "metadata": {
        "id": "oqHLBui6n9Nv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the CSVs\n",
        "users = pd.read_csv(\"/content/sample_data/Users.csv\")          # 100 rows\n",
        "content = pd.read_csv(\"/content/sample_data/Content.csv\")      # 100 rows\n",
        "interactions = pd.read_csv(\"/content/sample_data/interactions_labeled.csv\")  # 100 rows, each row is a user-content interaction\n",
        "\n",
        "# We'll assume we already computed or added a 'label' in interactions\n",
        "# via a compound engagement metric or a threshold approach.\n",
        "# If not, see earlier instructions for how to generate 'label'.\n"
      ],
      "metadata": {
        "id": "nJQ7yqL0oOtY"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Let's create a quick map: if content['topic'] == 'politics', we align with user topic_affinity_politics, etc.\n",
        "# We'll do a function that given a user row and content row, returns a naive \"match\" score.\n",
        "def naive_topic_score(user_row, content_row):\n",
        "    topic = content_row[\"topic\"]\n",
        "    if topic == \"politics\":\n",
        "        return user_row[\"topic_affinity_politics\"]\n",
        "    elif topic == \"technology\":\n",
        "        return user_row[\"topic_affinity_tech\"]\n",
        "    elif topic == \"sports\":\n",
        "        return user_row[\"topic_affinity_sports\"]\n",
        "    # ... in your real system you'd handle other topics (business, entertainment, etc.)\n",
        "    # We'll just return 0 if it's not one of those three.\n",
        "    else:\n",
        "        return 0.0\n",
        "\n",
        "# We also might want to filter out content if user is in a different region,\n",
        "# or if content has region_restriction that doesn't match the user, etc.\n",
        "# For simplicity, let's skip it or do a quick check.\n"
      ],
      "metadata": {
        "id": "yBOHiiaJoarA"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "user_ids = users[\"user_id\"].unique()\n",
        "content_ids = content[\"content_id\"].unique()\n",
        "\n",
        "candidate_dict = {}  # key: user_id, value: list of top content_id\n",
        "\n",
        "for uid in user_ids:\n",
        "    # Grab user row\n",
        "    user_row = users[users[\"user_id\"] == uid].iloc[0]\n",
        "\n",
        "    # For each piece of content, compute naive score\n",
        "    scores = []\n",
        "    for cid in content_ids:\n",
        "        c_row = content[content[\"content_id\"] == cid].iloc[0]\n",
        "        score = naive_topic_score(user_row, c_row)\n",
        "        scores.append((cid, score))\n",
        "\n",
        "    # Sort by descending score, pick top 20\n",
        "    scores.sort(key=lambda x: x[1], reverse=True)\n",
        "    top_candidates = [cid for (cid, sc) in scores[:20]]\n",
        "    candidate_dict[uid] = top_candidates\n",
        "\n",
        "# candidate_dict[u] now holds the list of content IDs for that user\n",
        "# In a real pipeline, you'd store these somewhere or proceed to Stage 2 next.\n"
      ],
      "metadata": {
        "id": "_sFsqrOTohD4"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import xgboost as xgb   # or \"import lightgbm as lgb\"\n",
        "\n",
        "# 1. Merge interactions with user and content data to get columns\n",
        "df_merged = interactions.merge(users, on=\"user_id\").merge(content, on=\"content_id\")\n",
        "\n",
        "# 2. We'll assume 'label' is in interactions. If you haven't computed it, do so first.\n",
        "#    If 'label' doesn't exist, see earlier code for computing a compound engagement metric threshold.\n",
        "\n",
        "# 3. We'll pick a few columns to be our features\n",
        "feature_cols = [\n",
        "    \"topic_affinity_politics\",\n",
        "    \"topic_affinity_tech\",\n",
        "    \"topic_affinity_sports\",\n",
        "    \"quality_score\"\n",
        "]\n",
        "X_data = df_merged[feature_cols]\n",
        "y_data = df_merged[\"label\"]  # 0 or 1\n",
        "\n",
        "# 4. Train/validation split\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_data, y_data, test_size=0.2, random_state=42)\n",
        "\n",
        "# 5. Train a basic XGBoost model\n",
        "gbdt = xgb.XGBClassifier(\n",
        "    n_estimators=100,\n",
        "    max_depth=3,\n",
        "    learning_rate=0.1,\n",
        "    use_label_encoder=False,\n",
        "    eval_metric=\"logloss\",\n",
        "    random_state=42,\n",
        "    early_stopping_rounds=5 # Move early_stopping_rounds to the XGBClassifier constructor\n",
        ")\n",
        "gbdt.fit(X_train, y_train, eval_set=[(X_val, y_val)]) # Remove early_stopping_rounds from fit()\n",
        "\n",
        "# Let's check accuracy quickly\n",
        "from sklearn.metrics import accuracy_score\n",
        "y_val_pred = gbdt.predict(X_val)\n",
        "acc = accuracy_score(y_val, y_val_pred)\n",
        "print(\"Validation Accuracy:\", acc)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Pd0Kc6Oolui",
        "outputId": "2ec3cba9-f810-4774-a4c7-0e4ccb45a94d"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0]\tvalidation_0-logloss:0.64370\n",
            "[1]\tvalidation_0-logloss:0.63996\n",
            "[2]\tvalidation_0-logloss:0.63499\n",
            "[3]\tvalidation_0-logloss:0.62238\n",
            "[4]\tvalidation_0-logloss:0.61711\n",
            "[5]\tvalidation_0-logloss:0.61348\n",
            "[6]\tvalidation_0-logloss:0.60472\n",
            "[7]\tvalidation_0-logloss:0.60463\n",
            "[8]\tvalidation_0-logloss:0.61131\n",
            "[9]\tvalidation_0-logloss:0.61919\n",
            "[10]\tvalidation_0-logloss:0.62538\n",
            "[11]\tvalidation_0-logloss:0.63238\n",
            "Validation Accuracy: 0.6363636363636364\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [22:48:00] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def gbdt_score_candidates(uid, candidate_list):\n",
        "    \"\"\"\n",
        "    Takes a user_id and a list of candidate content IDs.\n",
        "    Returns a list of (content_id, predicted_score).\n",
        "    \"\"\"\n",
        "    # find user row\n",
        "    user_row = users[users[\"user_id\"] == uid].iloc[0]\n",
        "\n",
        "    results = []\n",
        "    for cid in candidate_list:\n",
        "        c_row = content[content[\"content_id\"] == cid].iloc[0]\n",
        "\n",
        "        # build same features\n",
        "        row_feats = {\n",
        "            \"topic_affinity_politics\": user_row[\"topic_affinity_politics\"],\n",
        "            \"topic_affinity_tech\": user_row[\"topic_affinity_tech\"],\n",
        "            \"topic_affinity_sports\": user_row[\"topic_affinity_sports\"],\n",
        "            \"quality_score\": c_row[\"quality_score\"]\n",
        "        }\n",
        "\n",
        "        # convert to DataFrame\n",
        "        single_df = pd.DataFrame([row_feats])\n",
        "\n",
        "        # predict probability\n",
        "        proba = gbdt.predict_proba(single_df)[0,1]  # class=1 probability\n",
        "        results.append((cid, proba))\n",
        "\n",
        "    # Sort by descending proba\n",
        "    results.sort(key=lambda x: x[1], reverse=True)\n",
        "    return results\n",
        "\n",
        "# Example usage for user 1:\n",
        "top_20 = candidate_dict[1]  # from Stage 1\n",
        "stage2_ranked = gbdt_score_candidates(uid=1, candidate_list=top_20)\n",
        "print(\"GBDT Stage2 Ranking for User 1:\", stage2_ranked)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BFk4oOg0o7-L",
        "outputId": "50470a68-a4c5-40d2-dd36-e2f2303e8f6d"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GBDT Stage2 Ranking for User 1: [(np.int64(101), np.float32(0.42559618)), (np.int64(104), np.float32(0.42559618)), (np.int64(106), np.float32(0.42559618)), (np.int64(113), np.float32(0.42559618)), (np.int64(120), np.float32(0.42559618)), (np.int64(123), np.float32(0.42559618)), (np.int64(127), np.float32(0.42559618)), (np.int64(130), np.float32(0.42559618)), (np.int64(132), np.float32(0.42559618)), (np.int64(139), np.float32(0.42559618)), (np.int64(146), np.float32(0.42559618)), (np.int64(148), np.float32(0.42559618)), (np.int64(158), np.float32(0.42559618)), (np.int64(160), np.float32(0.42559618)), (np.int64(163), np.float32(0.42559618)), (np.int64(170), np.float32(0.42559618)), (np.int64(178), np.float32(0.42559618)), (np.int64(183), np.float32(0.42559618)), (np.int64(188), np.float32(0.42559618)), (np.int64(193), np.float32(0.42559618))]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import numpy as np\n",
        "\n",
        "# We'll reuse df_merged from above (the joined user+content+interaction dataset).\n",
        "X_data_nn = df_merged[feature_cols].values\n",
        "y_data_nn = df_merged[\"label\"].values\n",
        "\n",
        "# Train/val split\n",
        "X_train_nn, X_val_nn, y_train_nn, y_val_nn = train_test_split(X_data_nn, y_data_nn, test_size=0.2, random_state=42)\n",
        "\n",
        "# Build a small ANN\n",
        "model = keras.Sequential([\n",
        "    layers.Input(shape=(len(feature_cols),)),\n",
        "    layers.Dense(16, activation='relu'),\n",
        "    layers.Dense(8, activation='relu'),\n",
        "    layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "model.fit(X_train_nn, y_train_nn, validation_data=(X_val_nn, y_val_nn), epochs=10, batch_size=32)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lWPiT1KwpRID",
        "outputId": "bc6a3606-3684-410e-de0d-4951294f4818"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 226ms/step - accuracy: 0.4567 - loss: 0.6939 - val_accuracy: 0.4091 - val_loss: 0.6948\n",
            "Epoch 2/10\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - accuracy: 0.4509 - loss: 0.6930 - val_accuracy: 0.3636 - val_loss: 0.6935\n",
            "Epoch 3/10\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.4743 - loss: 0.6916 - val_accuracy: 0.3636 - val_loss: 0.6924\n",
            "Epoch 4/10\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - accuracy: 0.4940 - loss: 0.6911 - val_accuracy: 0.4091 - val_loss: 0.6915\n",
            "Epoch 5/10\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - accuracy: 0.5000 - loss: 0.6902 - val_accuracy: 0.3636 - val_loss: 0.6906\n",
            "Epoch 6/10\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.5314 - loss: 0.6876 - val_accuracy: 0.3636 - val_loss: 0.6896\n",
            "Epoch 7/10\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.5629 - loss: 0.6862 - val_accuracy: 0.4091 - val_loss: 0.6886\n",
            "Epoch 8/10\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.5885 - loss: 0.6851 - val_accuracy: 0.4091 - val_loss: 0.6875\n",
            "Epoch 9/10\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.5476 - loss: 0.6894 - val_accuracy: 0.5000 - val_loss: 0.6864\n",
            "Epoch 10/10\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.5986 - loss: 0.6819 - val_accuracy: 0.5455 - val_loss: 0.6852\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7a968083db10>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import numpy as np\n",
        "\n",
        "# We'll reuse df_merged from above (the joined user+content+interaction dataset).\n",
        "X_data_nn = df_merged[feature_cols].values\n",
        "y_data_nn = df_merged[\"label\"].values\n",
        "\n",
        "# Train/val split\n",
        "X_train_nn, X_val_nn, y_train_nn, y_val_nn = train_test_split(X_data_nn, y_data_nn, test_size=0.2, random_state=42)\n",
        "\n",
        "# Build a small ANN\n",
        "model = keras.Sequential([\n",
        "    layers.Input(shape=(len(feature_cols),)),\n",
        "    layers.Dense(16, activation='relu'),\n",
        "    layers.Dense(8, activation='relu'),\n",
        "    layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "model.fit(X_train_nn, y_train_nn, validation_data=(X_val_nn, y_val_nn), epochs=10, batch_size=32)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GS_xjE8mpWmg",
        "outputId": "4fc9d4b0-1df1-467a-f765-dc89141a2e46"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 223ms/step - accuracy: 0.6594 - loss: 0.6557 - val_accuracy: 0.6364 - val_loss: 0.6983\n",
            "Epoch 2/10\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - accuracy: 0.6672 - loss: 0.6525 - val_accuracy: 0.6364 - val_loss: 0.6968\n",
            "Epoch 3/10\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6672 - loss: 0.6493 - val_accuracy: 0.6364 - val_loss: 0.6953\n",
            "Epoch 4/10\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6516 - loss: 0.6542 - val_accuracy: 0.6364 - val_loss: 0.6935\n",
            "Epoch 5/10\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.6672 - loss: 0.6468 - val_accuracy: 0.6364 - val_loss: 0.6921\n",
            "Epoch 6/10\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.6321 - loss: 0.6570 - val_accuracy: 0.6364 - val_loss: 0.6918\n",
            "Epoch 7/10\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.6789 - loss: 0.6373 - val_accuracy: 0.6364 - val_loss: 0.6913\n",
            "Epoch 8/10\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.6594 - loss: 0.6439 - val_accuracy: 0.6364 - val_loss: 0.6911\n",
            "Epoch 9/10\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.6594 - loss: 0.6405 - val_accuracy: 0.6364 - val_loss: 0.6906\n",
            "Epoch 10/10\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.6516 - loss: 0.6445 - val_accuracy: 0.6364 - val_loss: 0.6904\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7a967bff7c90>"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def nn_score_candidates(uid, candidate_list):\n",
        "    results = []\n",
        "    user_row = users[users[\"user_id\"] == uid].iloc[0]\n",
        "\n",
        "    for cid in candidate_list:\n",
        "        c_row = content[content[\"content_id\"] == cid].iloc[0]\n",
        "        row_feats = [\n",
        "            user_row[\"topic_affinity_politics\"],\n",
        "            user_row[\"topic_affinity_tech\"],\n",
        "            user_row[\"topic_affinity_sports\"],\n",
        "            c_row[\"quality_score\"],\n",
        "        ]\n",
        "        X_input = np.array([row_feats], dtype=float)\n",
        "        prob = model.predict(X_input)[0,0]  # single numeric\n",
        "        results.append((cid, prob))\n",
        "\n",
        "    # sort descending\n",
        "    results.sort(key=lambda x: x[1], reverse=True)\n",
        "    return results\n",
        "\n",
        "# Let's say from Stage 2 we took the top 5:\n",
        "stage2_top5 = stage2_ranked[:5]  # [(cid, score), (cid, score), ...]\n",
        "final_stage3 = nn_score_candidates(uid=1, candidate_list=[cid for cid,_ in stage2_top5])\n",
        "\n",
        "print(\"Stage 3 Final Ranking for User 1:\", final_stage3)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bvw3x7kcpb4h",
        "outputId": "7b64ff34-62da-4e1c-fc0d-a361e8e84c91"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
            "Stage 3 Final Ranking for User 1: [(np.int64(106), np.float32(0.36139703)), (np.int64(113), np.float32(0.3536266)), (np.int64(101), np.float32(0.328912)), (np.int64(104), np.float32(0.32609668)), (np.int64(120), np.float32(0.32516098))]\n"
          ]
        }
      ]
    }
  ]
}